{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9: Camera calibration\n",
    "\n",
    "Written by: Enrique Mireles Gutiérrez  \n",
    "ID Number: 513944  \n",
    "Bachelor: ITR  \n",
    "Date: 2019-04-22  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Camera calibration is the process of estimating intrinsic and/or extrinsic parameters of the camera. These parameters describe the camera and its distortions. Intrinsic parameters are those that have to do with internal characteristics of the camera, such as the focal length, distortion, and the image center. Extrinsic parameters have to do with the position and orientation of the camera in space.  \n",
    "\n",
    "This lab report focuses on performing calibration for intrinsic parameters. Since no camera is built perfectly, the images obtained have distortions, also known as radial and tangential distortions. Therefore, by knowing how the image is distorted it is then possible to compensate for it and thus increase the accuracy of the camera. In applications, such as autonomous vehicles, calibrating the camera is essential.\n",
    "\n",
    "In order to calibrate the camera, several images of a standard calibration pattern are taken and then processed by optimization methods found in OpenCV in order to estimate the intrinsic parameters of the camera. Different types calibration patterns exist for this purpose. Nonetheless, a checkerboard pattern was chosen for its simplicity and effectiveness in this lab report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "This lab has the following objectives:\n",
    "- Design and print a checkerboard pattern for calibration.\n",
    "- Take images from the checkerboard pattern and use them to calibrate the camera.\n",
    "- Use the obtained calibration to undistort images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "\n",
    "This lab report is subdivided in smaller numbered tasks shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Printing and preparing the calibration pattern\n",
    "\n",
    "A checkerboard pattern was chosen for the calibration process. The pattern was generated using the website https://calib.io/pages/camera-calibration-pattern-generator. The settings used to generate the pattern were:\n",
    "- Target Type: Checkerboard\n",
    "- Board Width [mm]: 215.9 (8.5 in)\n",
    "- Board Height [mm]: 279.4 (11 in)\n",
    "- Rows: 11\n",
    "- Columns: 8\n",
    "- Checker Width [mm]: 20\n",
    "\n",
    "The board sizes where chosen such that they match a standard letter size paper. Furthermore, the amount of rows and columns was chosen to be odd and even respectively. The important part is that they aren’t both even or odd. By using the proposed values, a well sized checkerboard pattern could be printed on a standard letter size paper. The printer was configured to print as dark as possible and deactivated any scaling done to the printed image. \n",
    "\n",
    "The width of the checkers was then validated using digital calipers. The width of the checkers was actually 20mm. Finally, a glass sheet was used as a flat surface for placing the pattern. It was taped at the top and heavy books were left lying on top of the calibration pattern. After some hours, without lifting the paper, the calibration pattern was taped from all edges. Doing so left a flat pattern taped to the glass sheet. The calibration pattern was at this moment ready for its use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The camera and its focus\n",
    "\n",
    "The camera used was a Raspberry Pi Camera Module V2 (https://www.raspberrypi.org/products/camera-module-v2/) This module, as its name implies, runs on the Raspberry Pi and it will be the camera that runs on the autonomous vehicle. The camera comes with a fixed focus at infinity. However, by testing the camera it was shown that somehow the glue that holds the lens had stopped working and caused the lens to move out of focus. The camera was manually focused by turning the lens. It’s important that the images taken for calibration are in focus, otherwise the algorithms that analyze the image won’t find the pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Importing Libraries\n",
    "\n",
    "The following libraries are used throughout the lab report:\n",
    "- cv2: OpenCV library used for artificial vision.\n",
    "- numpy: library used for matrix operations.\n",
    "- os: library used for operating system interfaces.\n",
    "- datetime: library used for getting timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Constant definitions\n",
    "\n",
    "The following lines define the constants used throughout the lab report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = os.getcwd() + '/original/'\n",
    "CHESSBOARD_COLS = 10\n",
    "CHESSBOARD_ROWS = 7\n",
    "CHESSBOARD_CELL_WIDTH = 20\n",
    "CHESSBOARD_DIMENSIONS = (CHESSBOARD_COLS, CHESSBOARD_ROWS)\n",
    "FRAME_WIDTH = 1280\n",
    "FRAME_HEIGHT = 720\n",
    "FRAME_DIMENSIONS = (FRAME_WIDTH, FRAME_HEIGHT)\n",
    "\n",
    "# Get all images from source directory.\n",
    "IMAGES = []\n",
    "for r, d, f in os.walk(IMAGE_FOLDER):\n",
    "    for file in f:\n",
    "        IMAGES.append(IMAGE_FOLDER + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Taking calibration images\n",
    "\n",
    "A script was made that allowed a user to save pictures when the space-bar was pressed. Each picture was saved to an output folder, and with the help of an assistant, 31 different pictures were taken. Extra care was made to try to reduce glare on the calibration pattern (closing window blinds, turning on lamps, etc.). The position and orientation of the calibration pattern was changed in all directions and different -z depths were tested. All of this was done in order to obtain better calibration results.\n",
    "\n",
    "It's important to note that the code from this section requires a Raspberry Pi camera to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picamera.array import PiRGBArray\n",
    "from picamera import PiCamera\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Open raspberry pi's camera.\n",
    "camera = PiCamera()\n",
    "camera.resolution = FRAME_DIMENSIONS\n",
    "camera.framerate = 24\n",
    "rawCapture = PiRGBArray(camera, size=FRAME_DIMENSIONS)\n",
    "\n",
    "# Wait some time for it to init.\n",
    "time.sleep(0.1)\n",
    "\n",
    "# Counter for amount of images saved.\n",
    "image_count = 0\n",
    "\n",
    "# While loop - pi camera version.\n",
    "for frame in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "    \n",
    "    # Get image.\n",
    "    image = frame.array\n",
    "\n",
    "    # Display current image.\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "\n",
    "    # Wait for a key press and get next frame.\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    rawCapture.truncate(0)\n",
    "\n",
    "    # Check letter pressed.\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):\n",
    "        # If space is pressed, then get the current time and generate an output file name.\n",
    "        time = str(datetime.datetime.now()).split('.')[0]\n",
    "        output_filename = './output/' + time + '.jpg'\n",
    "\n",
    "        # Write image and log to command window.\n",
    "        cv2.imwrite(output_filename, image)\n",
    "        image_count += 1\n",
    "        print(str(image_count) + ' File written at: ' + output_filename)\n",
    "\n",
    "# Close all windows.    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images obtained in this section were compiled into a single .gif file. This was done with help from the popular image manipulation program Imagemagick. By going into the output folder and running the following command, all .jpg images in the current folder were compiled into a .gif:\n",
    "\n",
    "`convert -delay 30 -loop 0 *.jpg original.gif`\n",
    "\n",
    "This is the result:\n",
    "\n",
    "<img src=\"original.gif\" width=\"400\" alt=\"Original images.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Camera calibration\n",
    "\n",
    "The following program takes the images from the output folder and searches for the calibration pattern. If found, the calibration pattern is then displayed over the original image and used to calibrate the camera. At first, the delay on `waitKey` was increased to 2000 ms, and the code for calibrating the camera was commented out. This allowed the user to distinguish if an image didn’t work for the calibration pattern. However, all pictures taken worked flawlessly. The calibration code was uncommented and the delay  was reduced to 50 ms. Finally, the program outputs the camera matrix, the distortion matrix, the RMS error, and the rotation and translation output vectors of the checkerboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error 0.17605950343351903\n",
      "Camera matrix [[1.00612323e+03 0.00000000e+00 6.31540281e+02]\n",
      " [0.00000000e+00 1.00551440e+03 3.48207362e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion coefficients [[ 0.18541226 -0.32660915  0.00088513 -0.00038131 -0.02052374]]\n",
      "Output vector of rotation vectors [array([[ 0.34330688],\n",
      "       [-0.02407662],\n",
      "       [-1.6211368 ]]), array([[0.60826344],\n",
      "       [0.08193414],\n",
      "       [0.89317572]]), array([[ 0.28250445],\n",
      "       [-0.27637923],\n",
      "       [ 0.06208262]]), array([[-0.12331523],\n",
      "       [-0.38790127],\n",
      "       [-1.50296207]]), array([[ 0.11622997],\n",
      "       [-0.23183826],\n",
      "       [ 0.01983189]]), array([[ 0.16194306],\n",
      "       [ 0.15633236],\n",
      "       [-0.0125181 ]]), array([[-0.1688296 ],\n",
      "       [-0.58221824],\n",
      "       [ 0.70511442]]), array([[-0.18227042],\n",
      "       [-0.32888829],\n",
      "       [ 0.58915959]]), array([[ 0.04879359],\n",
      "       [-0.60104839],\n",
      "       [ 0.02237523]]), array([[ 0.35217944],\n",
      "       [-0.62736339],\n",
      "       [-1.35494189]]), array([[ 0.45701354],\n",
      "       [ 0.21990118],\n",
      "       [-0.30367036]]), array([[-0.36329063],\n",
      "       [-0.16367895],\n",
      "       [-0.04343954]]), array([[0.0367053 ],\n",
      "       [0.24708966],\n",
      "       [0.02333212]]), array([[ 0.33354417],\n",
      "       [-0.52728486],\n",
      "       [ 0.68119421]]), array([[ 0.0638283 ],\n",
      "       [-0.08059718],\n",
      "       [-0.01077991]]), array([[ 0.89771998],\n",
      "       [ 0.67972617],\n",
      "       [-1.44958501]]), array([[ 0.26793643],\n",
      "       [-0.3117604 ],\n",
      "       [ 0.05094209]]), array([[ 0.04675069],\n",
      "       [-0.01789812],\n",
      "       [ 0.02954159]]), array([[ 0.50086598],\n",
      "       [-0.23570184],\n",
      "       [ 0.0451956 ]]), array([[ 0.08570819],\n",
      "       [-0.09798408],\n",
      "       [-0.00348637]]), array([[ 0.30521338],\n",
      "       [-0.04425886],\n",
      "       [ 0.17327466]]), array([[ 0.18903024],\n",
      "       [-0.1491435 ],\n",
      "       [ 0.00719327]]), array([[ 0.19777773],\n",
      "       [-0.1616537 ],\n",
      "       [ 0.02335718]]), array([[ 0.28821716],\n",
      "       [-0.14850098],\n",
      "       [ 0.03314968]]), array([[-0.03675235],\n",
      "       [-0.32706366],\n",
      "       [-1.58296002]]), array([[ 0.22914024],\n",
      "       [-0.21743925],\n",
      "       [ 0.0067219 ]]), array([[ 0.12696697],\n",
      "       [-0.02501151],\n",
      "       [ 0.02374878]]), array([[ 0.07470215],\n",
      "       [-0.1916224 ],\n",
      "       [-0.07923777]]), array([[ 0.32573668],\n",
      "       [-0.49061764],\n",
      "       [ 0.83139344]]), array([[ 0.40296405],\n",
      "       [-0.16617327],\n",
      "       [ 0.07353548]]), array([[ 0.73159512],\n",
      "       [ 0.32671668],\n",
      "       [-1.51024381]])]\n",
      "Output vector of translation vectors [array([[-77.25069352],\n",
      "       [109.49706453],\n",
      "       [713.40455692]]), array([[  66.44799489],\n",
      "       [-194.90140756],\n",
      "       [ 888.33703275]]), array([[-277.1984538 ],\n",
      "       [  23.29876434],\n",
      "       [ 616.3947802 ]]), array([[-149.18206556],\n",
      "       [  77.39713728],\n",
      "       [ 705.44264914]]), array([[  91.23727004],\n",
      "       [-150.33359875],\n",
      "       [ 851.30527514]]), array([[ -89.89828681],\n",
      "       [-338.91109502],\n",
      "       [1204.84230503]]), array([[  13.78878998],\n",
      "       [-188.5326652 ],\n",
      "       [ 926.4804991 ]]), array([[-276.56911042],\n",
      "       [-201.64062515],\n",
      "       [ 895.36146902]]), array([[-358.08146864],\n",
      "       [-191.89471728],\n",
      "       [1051.40260257]]), array([[-229.80098652],\n",
      "       [  47.97033437],\n",
      "       [ 687.3535931 ]]), array([[ 127.75254942],\n",
      "       [-205.52574844],\n",
      "       [ 987.99564467]]), array([[-328.07901037],\n",
      "       [-144.93444301],\n",
      "       [ 917.79201323]]), array([[ -75.60095417],\n",
      "       [-190.72880282],\n",
      "       [1268.40616586]]), array([[-186.58397693],\n",
      "       [-227.90492982],\n",
      "       [1230.68466543]]), array([[  74.92440325],\n",
      "       [-119.671921  ],\n",
      "       [ 591.60505613]]), array([[-67.04047569],\n",
      "       [-44.23074802],\n",
      "       [776.53716948]]), array([[-104.26328347],\n",
      "       [  21.81834104],\n",
      "       [ 623.25158717]]), array([[-144.42261389],\n",
      "       [-194.92335426],\n",
      "       [1083.89821056]]), array([[-501.71322289],\n",
      "       [-324.0341639 ],\n",
      "       [1160.11796472]]), array([[-165.106526  ],\n",
      "       [-133.40425073],\n",
      "       [ 567.45608372]]), array([[ -39.80533852],\n",
      "       [-162.80928194],\n",
      "       [ 901.1476633 ]]), array([[-511.42441236],\n",
      "       [-335.76670088],\n",
      "       [1147.50607308]]), array([[-548.28924682],\n",
      "       [-348.21897813],\n",
      "       [1150.59928697]]), array([[-241.40326332],\n",
      "       [   9.36510192],\n",
      "       [ 813.09967656]]), array([[-116.88407348],\n",
      "       [  83.20320077],\n",
      "       [ 752.46808206]]), array([[137.02118761],\n",
      "       [  4.2393595 ],\n",
      "       [665.93899356]]), array([[-384.02296971],\n",
      "       [-170.32192648],\n",
      "       [ 847.19750047]]), array([[  82.09702179],\n",
      "       [-102.72301811],\n",
      "       [ 616.45985901]]), array([[-374.75781398],\n",
      "       [-259.65196695],\n",
      "       [1170.56922095]]), array([[-197.14768337],\n",
      "       [-207.41449058],\n",
      "       [ 797.65164031]]), array([[-65.89046311],\n",
      "       [  5.66380446],\n",
      "       [769.99995099]])]\n"
     ]
    }
   ],
   "source": [
    "# Init arrays for storing chessboard points.\n",
    "obj_points = []\n",
    "img_points = []\n",
    "\n",
    "# Generate an empty np array with the dimensions of the chessboard.\n",
    "# This array is required for calculating the camera distortion.\n",
    "pattern_points = np.zeros((np.prod(CHESSBOARD_DIMENSIONS), 3), np.float32)\n",
    "pattern_points[:, :2] = np.indices(CHESSBOARD_DIMENSIONS).T.reshape(-1, 2)\n",
    "pattern_points *= CHESSBOARD_CELL_WIDTH\n",
    "\n",
    "# Iterate through all images.\n",
    "for file in IMAGES:\n",
    "\n",
    "    # Read input image and convert to grayscale.\n",
    "    img = cv2.imread(file)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
    "\n",
    "    # Find chess board corners.\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD_DIMENSIONS, None)\n",
    "\n",
    "    # If chess board is found:\n",
    "    if (ret):\n",
    "        \n",
    "        # Find corners with better resolution.\n",
    "        corners2 = cv2.cornerSubPix(\n",
    "            gray, \n",
    "            corners, \n",
    "            (11, 11), \n",
    "            (-1, -1), \n",
    "            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, CHESSBOARD_CELL_WIDTH, 0.001)\n",
    "        )\n",
    "        \n",
    "        # Draw the found corners on the input image.\n",
    "        cv2.drawChessboardCorners(img, CHESSBOARD_DIMENSIONS, corners2, ret)\n",
    "        \n",
    "        # Saved the found data to an array.\n",
    "        img_points.append(corners2)\n",
    "        obj_points.append(pattern_points)\n",
    "        \n",
    "        # Uncomment to save output file.\n",
    "        # cv2.imwrite(file.replace('.', '-corners.'), img)\n",
    "        \n",
    "    else:\n",
    "        print('Chessboard not found: ' + file)\n",
    "\n",
    "    # Display image and wait 50 ms between frames.\n",
    "    cv2.imshow('input', img)\n",
    "    cv2.waitKey(50)\n",
    "\n",
    "# Calculate camera distortion.\n",
    "RMS, CAMERA_MATRIX, DISTORTION_COEFFICIENTS, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, FRAME_DIMENSIONS, None, None)\n",
    "\n",
    "# Display results.\n",
    "print('RMS error', RMS)\n",
    "print('Camera matrix', CAMERA_MATRIX)\n",
    "print('Distortion coefficients', DISTORTION_COEFFICIENTS)\n",
    "print('Output vector of rotation vectors', rvecs)\n",
    "print('Output vector of translation vectors', tvecs)\n",
    "\n",
    "# Close all windows.    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the output images from this step and compiling them into a single .gif yielded the following results:\n",
    "\n",
    "<img src=\"chessboard-corners.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Undistort images\n",
    "\n",
    "The following program takes the calibration and distortion matrix from the last section, and uses them to undistort the images taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window definitions.\n",
    "cv2.namedWindow('raw', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow('undistorted', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Iterate through all images.\n",
    "for file in IMAGES:\n",
    "\n",
    "    # Read input image.\n",
    "    img = cv2.imread(file)\n",
    "\n",
    "    # Generate the new camera matrix\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(CAMERA_MATRIX, DISTORTION_COEFFICIENTS, FRAME_DIMENSIONS, 1, FRAME_DIMENSIONS)\n",
    "    \n",
    "    # Undistort and display images.\n",
    "    dst = cv2.undistort(img, CAMERA_MATRIX, DISTORTION_COEFFICIENTS, None, newcameramtx)\n",
    "    cv2.imshow('raw', img)\n",
    "    cv2.imshow('undistorted', dst)\n",
    "    \n",
    "    # Uncomment to save undistorted images.\n",
    "    # cv2.imwrite(file.replace('.', '-undistorted.'), dst)\n",
    "    \n",
    "    # Delay between images.\n",
    "    cv2.waitKey(100)\n",
    "\n",
    "# Close all windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the output images from this step and compiling them into a single .gif yielded the following results:\n",
    "\n",
    "<img src=\"chessboard-corners-undistorted.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the results obtained in section 6, one can see that the calibration’s RMS error is around 0.176px, which is better than acceptable range set at 0.25px. This means that the calibration was done successfully and that it can be used for further applications. Moreover, it’s important to note that the center of the image doesn’t exactly lie on the image’s center. It is about 10px to the left, and 10px to the top from the theoretical center. The reasons behind this could be caused by the amount of distortion found at the edges and thus shift the center in a top-left direction.\n",
    "\n",
    "I’ve come to the conclusion that the amount of effort that one puts into the calibration process is inversely proportional to the RMS error. More pictures taken could yield better results. Also better lighting conditions or even a flatter calibration patter would increase accuracy. Nonetheless, by following simple techniques, such as flattening the calibration pattern with books, avoiding reflections on the image, and testing different orientations and positions of the pattern, produced good results on the first run.\n",
    "\n",
    "The following gifs toggle between the distorted and undistorted images. This allows the user to see how the image is changing and if distortions are properly corrected.\n",
    "\n",
    "<img src=\"animation.gif\">\n",
    "<img src=\"animation-2.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "- https://boofcv.org/index.php?title=Tutorial_Camera_Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I hereby affirm that I have done this activity with academic integrity._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
