{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Getting started with OpenCV for image and video processing\n",
    "\n",
    "Written by: Enrique Mireles Gutiérrez  \n",
    "ID Number: 513944  \n",
    "Bachelor: ITR  \n",
    "Date: 2019-02-08  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "OpenCV is a library used for artificial vision that contains more than 2500 different algorithms. It's an open source project that was created by Intel in 1999 and has grown to become the standard when it comes to image analysis and artificial vision algorithms. Now a days, the project continues to expand, adding day by day more algorithms to its repository.  \n",
    "\n",
    "Currently, OpenCV supports C++, Python, Java and is available for different operating systems such as Windows, Linux, OSX, Android, and others. OpenCV for Python is used throughout this lab. Compared to C++, Python is slower. Nonetheless, OpenCV presents the tools to create wrappers for writting code in C++ and therefore mantaining the performance of C++ and the ease of use of Python all together. All in all, OpenCV is a good tool for fast prototyping and testing artificial vision algorithms.  \n",
    "\n",
    "In order to write optimized code, help from other libraries is needed. An esential library for this is called Numpy. Numpy is a library used for manipulating matrixes and performing scientific computations. It has a powerful N-dimension array handler which excells the simple array implementations in raw Python. Therefore OpenCV + Numpy is esential for writing vision algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "This lab has the following objectives:\n",
    "- Getting started with images: Among the fundamental of image processing and computer vision application are the reading, visualisation and saving of processed images. Hence, in this section, you will learn how to read an image from disk, how to visualise it and how to write it back to disk.\n",
    "- Getting started with videos: You will focus on how to grab and visualise a live video sequence acquired from a web camera connected to your Raspberry Pi; in addition to this, you will learn how to read a video file from disk and do some video processing before this processed video is written to a video file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "\n",
    "This lab report is subdivided in smaller numbered programs shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries\n",
    "\n",
    "The following libraries are used throughout the lab report:\n",
    "- cv2: OpenCV library used for artificial vision.\n",
    "- numpy: Library used for matrix operations.\n",
    "- argparse: Used for parsing arguments passed through the console. In Jupyter, this library parses manually written arguments in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Constant definitions\n",
    "\n",
    "The following lines define the constants used throughout the lab report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_IN_FILENAME = '../fig/vehicular-traffic.jpg'\n",
    "IMAGE_OUT_FILENAME = 'vehicular-traffic-out.jpg'\n",
    "VIDEO_IN_FILENAME = '../fig/highway_right_solid_white_line_short.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Reading, visualizing and saving images\n",
    "\n",
    "Some key functions used in this section are:\n",
    "\n",
    "- `cv2.imread(filename[, flags])`\n",
    "     - Loads an image from a file.\n",
    "     - filename – Name of file to be loaded.\n",
    "     - flags – CV_LOAD_IMAGE_ANYDEPTH | CV_LOAD_IMAGE_COLOR | CV_LOAD_IMAGE_GRAYSCALE\n",
    "     - **returns** – Mat object.\n",
    "- `cv2.namedWindow(winname[, flags])`\n",
    "    - Creates a window.\n",
    "    - name – Name of the window in the window caption that may be used as a window identifier.\n",
    "    - flags – WINDOW_NORMAL | WINDOW_AUTOSIZE | WINDOW_OPENGL\n",
    "    - **returns** – None\n",
    "- `cv2.imshow(winname, mat)`\n",
    "    - Displays an image in the specified window.\n",
    "    - winname – Name of the window.\n",
    "    - image – Image to be shown.\n",
    "    - **returns** – None\n",
    "- `cv2.waitKey([delay])`\n",
    "    - Waits for a pressed key.\n",
    "    - delay – Delay in milliseconds. 0 is the special value that means “forever”.\n",
    "    - **returns** – the code of the pressed key or -1 if no key was pressed.\n",
    "- `cv2.imwrite(filename, img[, params])`\n",
    "    - Saves an image to a specified file.\n",
    "    - filename – Name of the file.\n",
    "    - image – Image to be saved.\n",
    "    - params – Format-specific save parameters encoded as pairs. Check docs.\n",
    "    - **returns** – retval\n",
    "- `cv2.destroyAllWindows()`\n",
    "    - Destroys all of the HighGUI windows.\n",
    "    - **returns** – None\n",
    "\n",
    "Information retrieved from: \n",
    "- https://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imwrite#cv2.imwrite\n",
    "- https://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly - bye!\n"
     ]
    }
   ],
   "source": [
    "# read in input image\n",
    "# alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "img_in = cv2.imread(IMAGE_IN_FILENAME, cv2.IMREAD_COLOR)\n",
    "\n",
    "# create a new window for image visualisation purposes\n",
    "# alternatively, you can use cv2.WINDOW_NORMAL\n",
    "cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# visualise input image\n",
    "cv2.imshow(\"input image\", img_in)\n",
    "\n",
    "# convert input image from colour to greyscale\n",
    "img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# visualise greyscale image\n",
    "cv2.imshow(\"greyscale image\", img_out)\n",
    "\n",
    "# wait for the user to press a key\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "# if user presses 's', the grayscale image is write to an image file\n",
    "if key == ord(\"s\"):\n",
    "\n",
    "    cv2.imwrite(IMAGE_OUT_FILENAME, img_out)\n",
    "    print('output image has been saved in %s' % IMAGE_OUT_FILENAME)\n",
    "\n",
    "# destroy windows to free memory  \n",
    "cv2.destroyAllWindows()\n",
    "print('windows have been closed properly - bye!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. A more elaborated program to read, visualise, and save an image\n",
    "\n",
    "Some key functions used in this section are:\n",
    "\n",
    "- `cv2.cvtColor(src, code[, dst[, dstCn]])`\n",
    "    - Converts an image from one color space to another.\n",
    "    - src – input image\n",
    "    - dst – output image of the same size and depth as src.\n",
    "    - code – color space conversion code. COLOR_BGR2GRAY, COLOR_BGR2XYZ, COLOR_BGR2YCrCb, COLOR_BGR2HSV, COLOR_BGR2HLS, COLOR_BGR2Lab, COLOR_BGR2Luv, COLOR_BayerBG2BGR\n",
    "    - dstCn – number of channels in the destination image.\n",
    "    - **returns** – Destination image\n",
    "- `argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True)`\n",
    "    - Create a new ArgumentParser object.\n",
    "    - prog – The name of the program (default: sys.argv[0])\n",
    "    - usage – The string describing the program usage (default: generated from arguments added to parser)\n",
    "    - description – Text to display before the argument help (default: none)\n",
    "    - epilog – Text to display after the argument help (default: none)\n",
    "    - parents – A list of ArgumentParser objects whose arguments should also be included\n",
    "    - formatter_class – A class for customizing the help output\n",
    "    - prefix_chars – The set of characters that prefix optional arguments (default: ‘-‘)\n",
    "    - fromfile_prefix_chars – The set of characters that prefix files from which additional arguments should be read (default: None)\n",
    "    - argument_default – The global default value for arguments (default: None)\n",
    "    - conflict_handler – The strategy for resolving conflicting optionals (usually unnecessary)\n",
    "    - add_help – Add a -h/--help option to the parser (default: True)\n",
    "    - **returns** – an ArgumentParser Object\n",
    "- `parser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])`\n",
    "    - Define how a single command-line argument should be parsed.\n",
    "    - name or flags – Either a name or a list of option strings, e.g. foo or -f, --foo.\n",
    "    - action – The basic type of action to be taken when this argument is encountered at the command line.\n",
    "    - nargs – The number of command-line arguments that should be consumed.\n",
    "    - const – A constant value required by some action and nargs selections.\n",
    "    - default – The value produced if the argument is absent from the command line.\n",
    "    - type – The type to which the command-line argument should be converted.\n",
    "    - choices – A container of the allowable values for the argument.\n",
    "    - required – Whether or not the command-line option may be omitted (optionals only).\n",
    "    - help – A brief description of what the argument does.\n",
    "    - metavar – A name for the argument in usage messages.\n",
    "    - dest – The name of the attribute to be added to the object returned by parse_args().\n",
    "    - **returns** – None\n",
    "- `vars([object])`\n",
    "    - Returns the \\_\\_dict__ attribute of the given object if the object has \\_\\_dict__ attribute.\n",
    "    - object – can be module, class, instance, or any object having \\_\\_dict__ attribute.\n",
    "    - **returns** – dict Object.\n",
    "\n",
    "\n",
    "Information retrieved from:\n",
    "- https://docs.opencv.org/3.0-beta/modules/imgproc/doc/miscellaneous_transformations.html#void%20cvtColor(InputArray%20src,%20OutputArray%20dst,%20int%20code,%20int%20dstCn)\n",
    "- https://docs.python.org/2/library/argparse.html#argparse.ArgumentParser.add_argument\n",
    "- https://www.programiz.com/python-programming/methods/built-in/vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows have been closed properly\n"
     ]
    }
   ],
   "source": [
    "def options():\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser('Read, visualise and write image into disk')\n",
    "    parser.add_argument('-i', '--in_image_name', help='input image name', required=True)\n",
    "    parser.add_argument('-o', '--out_image_name', help='output image name', required=True)\n",
    "    args = vars(parser.parse_args())\n",
    "    return args\n",
    "\n",
    "def processing_image(img_in_name, img_out_name):\n",
    "\n",
    "    # read in image from file\n",
    "    # alternatively, you can use cv2.IMREAD_GRAYSCALE\n",
    "    img_in = cv2.imread(img_in_name, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # verify that image exists\n",
    "    if img_in is None:\n",
    "        print('ERROR: image ', img_in_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # convert input image from colour to grayscale\n",
    "    img_out = cv2.cvtColor(img_in, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    # that option will allow you for window resizing\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # visualise input and output image\n",
    "    cv2.imshow(\"input image\", img_in)\n",
    "    cv2.imshow(\"output image\", img_out)\n",
    "\n",
    "    # wait for the user to press a key\n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    # if user pressed 's', the grayscale image is write to disk\n",
    "    if key == ord(\"s\"):\n",
    "        cv2.imwrite(img_out_name, img_out)\n",
    "        print('output image has been saved in %s' % img_out)\n",
    "\n",
    "    # destroy windows to free memory  \n",
    "    cv2.destroyAllWindows()\n",
    "    print('windows have been closed properly')\n",
    "\n",
    "# main function\n",
    "def main():    \n",
    "\n",
    "    # uncomment these lines when running on jupyter notebook\n",
    "    # and comment when running as a script on linux terminal\n",
    "    args = {\n",
    "            \"in_image_name\": IMAGE_IN_FILENAME,\n",
    "            \"out_image_name\": IMAGE_OUT_FILENAME\n",
    "            }\n",
    "    in_image_name = args['in_image_name']\n",
    "    out_image_name = args['out_image_name']\n",
    "\n",
    "    # comment the following line when running on jupyter notebook\n",
    "    # and uncomment when running as a script on linux terminarl\n",
    "    # args = options()\n",
    "\n",
    "    # call processing image\n",
    "    processing_image(in_image_name, out_image_name)\n",
    "\n",
    "\n",
    "# run first\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Basic program to capture live video from camera\n",
    "\n",
    "Some key functions used in this section are:\n",
    "\n",
    "- `cv2.VideoCapture([filename, device])`\n",
    "    - VideoCapture constructors.\n",
    "    - filename – name of the opened video file.\n",
    "    - device – id of the opened video capturing device\n",
    "    - **returns** – <VideoCapture \\object> \n",
    "- `cv2.VideoCapture.read()`\n",
    "    - Grabs, decodes and returns the next video frame.\n",
    "    - **returns** – retval, image \n",
    "- `cv2.VideoCapture.release()`\n",
    "    - Closes video file or capturing device.\n",
    "    - **returns** – None\n",
    "    \n",
    "Information retrieved from:\n",
    "- https://docs.opencv.org/3.0-beta/modules/videoio/doc/reading_and_writing_video.html?highlight=videocapture#videocapture-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# main loop\n",
    "while(True):\n",
    "\n",
    "    # capture new frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert from colour to grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # visualise image\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # wait for the user to press 'q' to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Basic program to capture live video from Raspberry Pi camera\n",
    "\n",
    "Some key functions used in this section are:\n",
    "\n",
    "- `PiCamera(camera_num=0, stereo_mode='none', stereo_decimate=False, resolution=None, framerate=None, sensor_mode=0, led_pin=None, clock_mode='reset', framerate_range=None)`\n",
    "    - Provides a pure Python interface to the Raspberry Pi’s camera module.\n",
    "    - **returns** – PiCamera object\n",
    "- `PiCamera.resolution`\n",
    "    - Retrieves or sets the resolution at which image captures, video recordings, and previews will be captured.\n",
    "- `PiCamera.framerate`\n",
    "    - Retrieves or sets the framerate at which video-port based image captures, video recordings, and previews will run.\n",
    "- `PiRGBArray(camera, size=None)`\n",
    "    - Produces a 3-dimensional RGB array from an RGB capture.\n",
    "    - camera – PiCamera object.\n",
    "    - **returns** – array\n",
    "- `time.sleep(t)`\n",
    "    - Suspends execution for the given number of seconds.\n",
    "    - t − This is the number of seconds execution to be suspended.\n",
    "    - **returns** – None\n",
    "- `np.float32(c)`\n",
    "    - Create a single precision float\n",
    "    - c – number to convert.\n",
    "    - **returns** – single precision float.\n",
    "- `cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])`\n",
    "    - image – 8-bit input image.\n",
    "    - edges – output edge map; single channels 8-bit image, which has the same size as image .\n",
    "    - threshold1 – first threshold for the hysteresis procedure.\n",
    "    - threshold2 – second threshold for the hysteresis procedure.\n",
    "    - apertureSize – aperture size for the Sobel() operator.\n",
    "    - L2gradient – a flag, indicating whether a more accurate L2 norm.\n",
    "    - **returns** – edges  \n",
    "- `ord(c)`\n",
    "    - Returns an integer representing Unicode code point for the given Unicode character.\n",
    "    - c – character string of length 1 whose Unicode code point is to be found.\n",
    "    - **returns** – int\n",
    "\n",
    "At the moment, no Raspberry Pi with Raspicam is available. Therefore, this section has no code to execute.\n",
    "\n",
    "Information retrieved from:\n",
    "- https://picamera.readthedocs.io/en/release-1.10/api_array.html#pirgbarray\n",
    "- https://www.tutorialspoint.com/python/time_sleep.htm\n",
    "- https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html\n",
    "- https://www.programiz.com/python-programming/methods/built-in/ord\n",
    "- https://docs.opencv.org/3.0-beta/modules/imgproc/doc/feature_detection.html?highlight=cv2.canny#cv2.Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. A more elaborated program to capture, process and visualise video\n",
    "\n",
    "Some key functions used in this section are:\n",
    "\n",
    "- `cv2.videoCapture.isOpened()`\n",
    "    - Returns true if video capturing has been initialized already.\n",
    "    - **returns** – retval\n",
    "- `cv2.videoCapture.get(propId)`\n",
    "    - propId – Property identifier. \n",
    "    - Returns the specified VideoCapture property\n",
    "    - **returns** – retval\n",
    "- `cv2.flip(src, flipCode[, dst])`\n",
    "    - Flips a 2D array around vertical, horizontal, or both axes\n",
    "    - src – input array.\n",
    "    - dst – output array of the same size and type as src.\n",
    "    - flipCode – a flag to specify how to flip the array; 0 means flipping around the x-axis and positive value means flipping around y-axis. Negative value (for example, -1) means flipping around both axes.\n",
    "    - **returns** – dst\n",
    "    \n",
    "Information retrieved from:\n",
    "- https://docs.opencv.org/3.0-beta/modules/videoio/doc/reading_and_writing_video.html?highlight=cv2.videocapture.isopened#videocapture-get\n",
    "- https://docs.opencv.org/3.0-beta/modules/core/doc/operations_on_arrays.html?highlight=flip#cv2.flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video specifications:\n",
      "\tframe width:  640.0\n",
      "\tframe height:  480.0\n",
      "\tframe rate:  30.0\n",
      "\tbrightness:  0.5019607843137255\n",
      "\tcontrast:  0.12549019607843137\n",
      "\tsaturation:  0.64\n",
      "\thue:  -1.0\n",
      "\texposure:  inf\n",
      "\n",
      "capturing video ...\n",
      "closing camera ...\n",
      "camera closed\n",
      "program finished - bye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def configure_videoCapture(device_index):\n",
    "\n",
    "    \"\"\"\n",
    "    Configure video capture object to handle video device.\n",
    "\n",
    "    Parameters\n",
    "        device_index: int value indicating the index number to access camera\n",
    "\n",
    "    Returns\n",
    "        cap: videoCapture-type object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a videoCapture object and returns either a True or False\n",
    "    cap = cv2.VideoCapture(device_index)\n",
    "\n",
    "    # if camera could not be opened, it displays an error and exits\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera could not be opened\")\n",
    "        exit()\n",
    "\n",
    "    # return videoCapture object 'cap'\n",
    "    return cap\n",
    "\n",
    "\n",
    "def print_video_frame_specs(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Print video specifications such as video frame width and height, fps,\n",
    "    brightness, contrast, saturation, gain, and exposure.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: this definition only prints information on the command line\n",
    "              window.\n",
    "    \"\"\"    \n",
    "\n",
    "    # retrieve video properties\n",
    "    ret, frame = cap.read()\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # verify that frame was properly captured\n",
    "    if ret == False:\n",
    "        print(\"ERROR: current frame could not be read\")\n",
    "        exit()\n",
    "\n",
    "    else: # if so, video frame stats are displayed\n",
    "\n",
    "        # print video frames specifications\n",
    "        print('\\nVideo specifications:')\n",
    "        print('\\tframe width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('\\tframe height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        print('\\tframe rate: ', cap.get(cv2.CAP_PROP_FPS))\n",
    "        print('\\tbrightness: ', cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "        print('\\tcontrast: ', cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "        print('\\tsaturation: ', cap.get(cv2.CAP_PROP_SATURATION))\n",
    "        print('\\thue: ', cap.get(cv2.CAP_PROP_GAIN))\n",
    "        print('\\texposure: ', cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "\n",
    "    # return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def capture_and_process_video(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Capture live video from a camera connected to your computer. Each frame is\n",
    "    flipped and visualised together with the original frame on separate windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create a new window for image purposes\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)  # alternatively, you can use cv2.WINDOW_NORMAL\n",
    "    cv2.namedWindow(\"output image\", cv2.WINDOW_AUTOSIZE) # that option will allow you for window resizing\n",
    "\n",
    "\n",
    "    # main loop\n",
    "    print('\\ncapturing video ...')\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        # capture frame by frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")\n",
    "            break\n",
    "\n",
    "        # if frame was properly captured, it is converted\n",
    "        # from a colour to a grayscale image\n",
    "        frame_out = cv2.flip(frame,0)\n",
    "\n",
    "        # visualise current frame and grayscale frame\n",
    "        cv2.imshow(\"input image\", frame)\n",
    "        cv2.imshow(\"output image\", frame_out)\n",
    "\n",
    "\n",
    "        # wait for the user to press a key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def free_memory(cap):\n",
    "\n",
    "    \"\"\"\n",
    "    Free memory by releasing videoCapture 'cap' and by destroying/closing all\n",
    "    open windows.\n",
    "\n",
    "    Parameters\n",
    "        cap: video capture object\n",
    "\n",
    "    Returns\n",
    "        None: none\n",
    "    \"\"\"\n",
    "\n",
    "    # when finished, release the VideoCapture object and close windows to free memory\n",
    "    print('closing camera ...')\n",
    "    cap.release()\n",
    "    print('camera closed')\n",
    "    cv2.destroyAllWindows()\n",
    "    print('program finished - bye!\\n')\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_pipeline(device_index=0):\n",
    "    \"\"\"\n",
    "    Run pipeline to capture, process and visualise both the original frame and\n",
    "    processed frame.\n",
    "\n",
    "    Parameters\n",
    "        device_index: device index - 0 default\n",
    "\n",
    "    Returns\n",
    "        arg: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline\n",
    "    cap = configure_videoCapture(device_index)\n",
    "    print_video_frame_specs(cap)\n",
    "    capture_and_process_video(cap)\n",
    "    free_memory(cap)\n",
    "\n",
    "    # return none\n",
    "    return None\n",
    "\n",
    "\n",
    "# run pipeline    \n",
    "run_pipeline(device_index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Basic program to play a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# create a VideoCapture object and specify video file to be read\n",
    "cap = cv2.VideoCapture(VIDEO_IN_FILENAME)\n",
    "\n",
    "# main loop\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # validate that frame was capture correctly\n",
    "    if ret:\n",
    "\n",
    "        # convert frame from colour to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # show current frame\n",
    "        cv2.imshow('frame',gray)\n",
    "\n",
    "    # wait for the user to press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "In this lab, basic operations in OpenCV were learned. These included reading images, opening video streams, and displaying them in windows. After that, some basic modifications and file savings were made. I believe the key in learning OpenCV is in getting to know the methods used in the library. My first experience with it was more than 6 years ago with a Raspberry Pi, and I remember the experience felt really overwhelming. Nonetheless, with the constant boom of artificial intelligence and computer vision aided algorithms I believe this lab will prove itself really useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- NumPy. (2018). NumPy. Retrieved from: http://www.numpy.org/\n",
    "- OpenCV. (2019). About. Retrieved from: https://opencv.org/about.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I hereby affirm that I have done this activity with academic integrity._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
